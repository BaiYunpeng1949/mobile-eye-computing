{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537937a8",
   "metadata": {},
   "source": [
    "# The Pupil Features Extracted in Batch Pipeline.\n",
    "## Introuduction\n",
    "The features to be extracted includes blinking rate and chunks of wavelet coefficients.\n",
    "\n",
    "## Reference\n",
    "1. The previous codes.https://github.com/BaiYunpeng1949/MobileEyeComputing/tree/master/ProcessDataNTestAlgorithm\n",
    "2. TODO: add papers here.\n",
    "3. My work: https://docs.google.com/document/d/1oLv3oJQLjst1_pYgd_UA3RRL1fRGSbZ6uvlMuxmZR2k/edit#heading=h.r01ccf7ox05g\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75874ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from os import walk\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62025f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(ax, data1, data2, param_dict):\n",
    "    out = ax.plot(data1, data2, **param_dict)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c74efe",
   "metadata": {},
   "source": [
    "## [Suspended] File-wise/Task-wise Data Pre-processing\n",
    "### Left and Right Eye Synchronization\n",
    "Referenced from the previous work located as: https://github.com/BaiYunpeng1949/MobileEyeComputing/blob/master/ProcessDataNTestAlgorithm/LeftRightEyesSyncData.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312ae7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pre_sync(left_eye_file_path, right_eye_file_path):   \n",
    "    # Configure the parameters\n",
    "    entity_dwt_align = 'Timestamp'\n",
    "    entity_dwt_apply_dia = 'Diameter'\n",
    "    entity_dwt_apply_conf = 'Confidence'\n",
    "    left_eye = 'left'\n",
    "    right_eye = 'right'\n",
    "    \n",
    "    # Tag labels\n",
    "    SAMPLING_RATE_LEFT = int((left_eye_file_path.split('_')[-1]).split('Hz')[0])\n",
    "    data_left = pd.read_csv(left_eye_file_path)\n",
    "\n",
    "    SAMPLING_RATE_RIGHT = int((right_eye_file_path.split('_')[-1]).split('Hz')[0])\n",
    "    data_right = pd.read_csv(right_eye_file_path)\n",
    "    \n",
    "    df_left = data_left[['Timestamp','Confidence','Diameter','Event']].copy()\n",
    "    df_right = data_right[['Timestamp','Confidence','Diameter','Event']].copy()\n",
    "    \n",
    "    # Determine the left and right eye data's size first: which one is bigger?\n",
    "    # Identify the number of elements in the left/right eyes data. If one applies the up-sampling method, the larger eye needs to be put in the first argument.\n",
    "    len_left = len(df_left)\n",
    "    len_right = len(df_right)\n",
    "    if len_left >= len_right:\n",
    "        df_reference = df_left.copy()  # df_reference: the one that being put in the first argument, as a reference.\n",
    "        df_alignment = df_right.copy() # df_alignment: the one that being put in the second argument, to be aligned to the reference.\n",
    "        df_origin = df_left.copy()\n",
    "        SR_SYNC = SAMPLING_RATE_LEFT\n",
    "    elif len_left < len_right:\n",
    "        df_reference = df_right.copy()\n",
    "        df_alignment = df_left.copy()\n",
    "        df_origin = df_right.copy()\n",
    "        SR_SYNC = SAMPLING_RATE_RIGHT\n",
    "    \n",
    "    # Calculate for warping.\n",
    "    distance, path = fastdtw(df_reference[entity_dwt_align], df_alignment[entity_dwt_align], dist=euclidean)\n",
    "    \n",
    "    return path, df_reference, df_alignment, entity_dwt_apply_dia, entity_dwt_apply_conf, df_origin, SR_SYNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab963e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function scnchronize and align/merge 2 eyes' numerical values, including diamter and confidence values.\n",
    "# The method of getting the average/mean value of 2 eyes' data as computing target is referenced from the mention in LHIPA.\n",
    "def _synchronize_merge_data(path_dwt, df_reference, df_alignment, entity_dwt_apply):\n",
    "    # Synchronize\n",
    "    data_sync = []\n",
    "    for i in range(0, len(path_dwt)):\n",
    "        data_sync.append([path_dwt[i][0],  # The index column is for dropping out duplicates.\n",
    "                         df_reference[entity_dwt_apply].iloc[path_dwt[i][0]],\n",
    "                         df_alignment[entity_dwt_apply].iloc[path_dwt[i][1]]])\n",
    "    df_sync = pd.DataFrame(data=data_sync,\n",
    "                           columns=['Index', \n",
    "                                    'Reference '+entity_dwt_apply, \n",
    "                                    'Alignment '+entity_dwt_apply]).dropna()\n",
    "    df_sync = df_sync.drop_duplicates(subset=['Index']) # Drop the duplicates according to the index of the reference.\n",
    "    df_sync = df_sync.reset_index(drop=True)\n",
    "    # Merge/Align\n",
    "    df_sync['Avg'+entity_dwt_apply] = df_sync.loc[:, ['Reference '+entity_dwt_apply, 'Alignment '+entity_dwt_apply]].mean(axis = 1)\n",
    "    \n",
    "    return df_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b321f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synchronize the given 2 eyes' data.\n",
    "def sync(left_eye_file_path, right_eye_file_path):\n",
    "    # Prepare for the sychronization.\n",
    "    path, df_reference, df_alignment, entity_dwt_apply_dia, entity_dwt_apply_conf, df_origin, SR_SYNC = _pre_sync(left_eye_file_path = left_eye_file_path, \n",
    "                                                                                                                  right_eye_file_path = right_eye_file_path)\n",
    "\n",
    "    \n",
    "    # Synchronize, merge, and label data.\n",
    "    df_sync_dia = _synchronize_merge_data(path_dwt=path,\n",
    "                                          df_reference=df_reference,\n",
    "                                          df_alignment=df_alignment,\n",
    "                                          entity_dwt_apply=entity_dwt_apply_dia)\n",
    "    df_sync_conf = _synchronize_merge_data(path_dwt=path,\n",
    "                                           df_reference=df_reference,\n",
    "                                           df_alignment=df_alignment,\n",
    "                                           entity_dwt_apply=entity_dwt_apply_conf)\n",
    "    \n",
    "    # Integrate into one dataframe.\n",
    "    df_sync = pd.DataFrame()\n",
    "    df_sync['Timestamp'] = df_origin['Timestamp']\n",
    "    df_sync['Confidence'] = df_sync_conf['AvgConfidence']\n",
    "    df_sync['Diameter'] = df_sync_dia['AvgDiameter']\n",
    "    df_sync['Event'] = df_origin['Event']\n",
    "    \n",
    "    # Output and save into a csv file.\n",
    "    df_export = df_sync.copy()\n",
    "    file_name = left_eye_file_path.split('/')[-2:]\n",
    "\n",
    "    folder_path = '../Data/PreprocessedData/' + file_name[0] + '/'\n",
    "    if os.path.exists(folder_path) is False:\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    write_file_name = 'synchronized_' + str(SR_SYNC) + 'Hz.csv'\n",
    "    write_file_path = folder_path + write_file_name\n",
    "    df_export.to_csv(write_file_path)\n",
    "    \n",
    "    return df_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df6e65",
   "metadata": {},
   "source": [
    "### Deblinks and Blinking Rate Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb84ba7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bcdd438",
   "metadata": {},
   "source": [
    "### Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab57a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "566c00a3",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a4b396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d87d550",
   "metadata": {},
   "source": [
    "### Artefact Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900859ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2abbd51",
   "metadata": {},
   "source": [
    "## Wavelet Coefficient Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00a372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7ecf5ec",
   "metadata": {},
   "source": [
    "## Run in Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d561063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument configuration.\n",
    "CONF_2DMODE = '2D'\n",
    "CONF_LEFT = 'left'\n",
    "CONF_RIGHT = 'right'\n",
    "raw_data_path = '../Data/RawData4ML/VersionOctober/' # In this case, the dirpath is mypath, dirnames contains sub-folders's names I need, and no filenames since there is no files there.\n",
    "dir_features = '../Data/Results/'\n",
    "\n",
    "# Create a dataframe to store results details. TODO: to be modified to align to short time windows. Columns - features; Rows - short segmentations.\n",
    "df_features = pd.DataFrame(columns=['Filename', 'Max level value', \n",
    "                                   'IPA 2', 'IPA 3', 'IPA 4', 'IPA 5', 'IPA 6', 'IPA 7', 'IPA 8', 'IPA 9',\n",
    "                                   'LHIPA 2', 'LHIPA 3', 'LHIPA 4', 'LHIPA 5', 'LHIPA 6', 'LHIPA 7', 'LHIPA 8', 'LHIPA 9'])  # Needs to be changed according to requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7705e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all directory names\n",
    "dirs_list = []\n",
    "for (dir_path, dir_names, file_names) in walk(raw_data_path):\n",
    "    dirs_list.extend(dir_names)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7524cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 00:39:01.333 INFO    numexpr.utils: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-11-14 00:39:01.334 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Traverse all the file names in a given directory.\n",
    "for dir_name in dirs_list:\n",
    "    dir_path = raw_data_path + dir_name + '/'\n",
    "    file_names_list = []\n",
    "    for (_, _, file_names) in walk(dir_path):\n",
    "        file_names_list.extend(file_names)\n",
    "    \n",
    "    # Find the targetted files.\n",
    "    for file_name in file_names:\n",
    "        if CONF_2DMODE in file_name:\n",
    "            if CONF_LEFT in file_name:\n",
    "                file_path_left = dir_path + file_name\n",
    "            elif CONF_RIGHT in file_name:\n",
    "                file_path_right = dir_path + file_name\n",
    "      \n",
    "    # We suspended the two eyes' synchronization for extracting more information because the difference of two pupil was also recognized as an indicator of cognitive workload.\n",
    "    # TODO: reference is needed here.\n",
    "    # Synchronize 2 eyes' data.\n",
    "    df_sync = sync(left_eye_file_path=file_path_left, \n",
    "                   right_eye_file_path=file_path_right)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48dda6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>352723.490801</td>\n",
       "      <td>0.582239</td>\n",
       "      <td>42.578041</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352723.498762</td>\n",
       "      <td>0.595818</td>\n",
       "      <td>42.676222</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352723.509503</td>\n",
       "      <td>0.735812</td>\n",
       "      <td>44.720957</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>352723.517714</td>\n",
       "      <td>0.731661</td>\n",
       "      <td>44.501411</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352723.529483</td>\n",
       "      <td>0.594411</td>\n",
       "      <td>44.662136</td>\n",
       "      <td>default</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5323</th>\n",
       "      <td>352783.026782</td>\n",
       "      <td>0.568662</td>\n",
       "      <td>46.947025</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>352783.036907</td>\n",
       "      <td>0.547047</td>\n",
       "      <td>47.382788</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5325</th>\n",
       "      <td>352783.046935</td>\n",
       "      <td>0.657286</td>\n",
       "      <td>47.375761</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5326</th>\n",
       "      <td>352783.060591</td>\n",
       "      <td>0.539107</td>\n",
       "      <td>46.407917</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5327</th>\n",
       "      <td>352783.070567</td>\n",
       "      <td>0.493199</td>\n",
       "      <td>46.925657</td>\n",
       "      <td>sitting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5328 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  Confidence   Diameter    Event\n",
       "0     352723.490801    0.582239  42.578041  default\n",
       "1     352723.498762    0.595818  42.676222  default\n",
       "2     352723.509503    0.735812  44.720957  default\n",
       "3     352723.517714    0.731661  44.501411  default\n",
       "4     352723.529483    0.594411  44.662136  default\n",
       "...             ...         ...        ...      ...\n",
       "5323  352783.026782    0.568662  46.947025  sitting\n",
       "5324  352783.036907    0.547047  47.382788  sitting\n",
       "5325  352783.046935    0.657286  47.375761  sitting\n",
       "5326  352783.060591    0.539107  46.407917  sitting\n",
       "5327  352783.070567    0.493199  46.925657  sitting\n",
       "\n",
       "[5328 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sync"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

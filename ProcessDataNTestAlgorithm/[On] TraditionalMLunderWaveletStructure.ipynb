{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c0caa8",
   "metadata": {},
   "source": [
    "## Traditional ML classification models under wavelet analysis structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb78a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy \n",
    "import argparse\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae526d",
   "metadata": {},
   "source": [
    "### Implementations\n",
    "#### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005e23c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations - Feature names\n",
    "LOWLUX = 'lowlux'\n",
    "MIDLUX = 'middlelux'\n",
    "HIGHLUX = 'highlux'\n",
    "NOBACK = 'nothing'\n",
    "ONEBACK = 'ONEBACK'\n",
    "TWOBACK = 'TWOBACK'\n",
    "THREEBACK = 'THREEBACK'\n",
    "FILENAME = 'Filename'\n",
    "IPA2 = 'IPA 2'\n",
    "INDEX = 'index'\n",
    "LUX = 'Luminance'\n",
    "LABELS = 'Labels'\n",
    "ISBLINK_LEFT = 'isBlink-Left'\n",
    "ISBLINK_RIGHT = 'isBlink-Right'\n",
    "PID = 'PID'\n",
    "AVE_DM = 'Averaged Diameter'\n",
    "DIFF_DM = 'Difference Diameter'\n",
    "\n",
    "IPA_LEFT = 'IPA Left'\n",
    "IPA_RIGHT = 'IPA Right'\n",
    "\n",
    "LHIPA_LEFT = 'LHIPA Left'\n",
    "LHIPA_RIGHT = 'LHIPA Right'\n",
    "\n",
    "MEAN_LEFT = 'Mean Left'\n",
    "MEAN_RIGHT = 'Mean Right'\n",
    "\n",
    "STD_LEFT = 'STD Left'\n",
    "STD_RIGHT = 'STD Right'\n",
    "\n",
    "SKEW_LEFT = 'Skew Left'\n",
    "SKEW_RIGHT = 'Skew Right'\n",
    "\n",
    "MAX_LEFT = 'MAX Left'\n",
    "MAX_RIGHT = 'MAX Right'\n",
    "\n",
    "MED_LEFT = 'Med Left'\n",
    "MED_RIGHT = 'Med Right'\n",
    "\n",
    "VAR_LEFT = 'Var Left'\n",
    "VAR_RIGHT = 'Var Right'\n",
    "\n",
    "\n",
    "# Model names.\n",
    "KNN = 'KNN'\n",
    "SVM = 'SVM'\n",
    "RF = 'Random Forest'\n",
    "\n",
    "# # Training and testing ratio.\n",
    "# TEST_SIZE_PCT = 0.1\n",
    "\n",
    "# # Hyper-parameters tuning.\n",
    "# # Setting thresholds for 2 eyes' blinking rates.\n",
    "# THRES_BLINKING_RATE = 1.00 # The default value.\n",
    "# # The random forest layers.\n",
    "# RF_DEPTH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd971e00",
   "metadata": {},
   "source": [
    "#### Encoder\n",
    "\n",
    "This part encodes features into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e40da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Lux and Labeling\n",
    "def encode(df_input):\n",
    "    luxes = []\n",
    "    nbacks = []\n",
    "#     df_numeric_features = df_raw_features.copy()\n",
    "    df_numeric_features = df_input.copy()\n",
    "\n",
    "    for index, row in df_numeric_features.iterrows():\n",
    "        # Label luxes\n",
    "        if LOWLUX in row[LUX]:\n",
    "            luxes.append(1)\n",
    "        elif MIDLUX in row[LUX]:\n",
    "            luxes.append(2)\n",
    "        elif HIGHLUX in row[LUX]:\n",
    "            luxes.append(3)\n",
    "\n",
    "        # Label task difficulties\n",
    "        if NOBACK in row[LABELS]:\n",
    "            nbacks.append(0)\n",
    "        elif ONEBACK in row[LABELS]:\n",
    "            nbacks.append(1)\n",
    "        elif TWOBACK in row[LABELS]:\n",
    "            nbacks.append(2)\n",
    "        elif THREEBACK in row[LABELS]:\n",
    "            nbacks.append(3)\n",
    "\n",
    "    df_numeric_features[LUX] = luxes\n",
    "    df_numeric_features[LABELS] = nbacks\n",
    "    \n",
    "    # Output the results\n",
    "    df_output = df_numeric_features.copy()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470af68",
   "metadata": {},
   "source": [
    "#### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "174a70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df_labels_IPA2, hue=LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce1adb",
   "metadata": {},
   "source": [
    "#### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ef57894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show machine learning models' performance.\n",
    "def show_performance(y_true, y_pred, model_name):\n",
    "    # Get the accuracy score.\n",
    "    acc_score = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Get the F1 score.\n",
    "    # I chose the macro for worrying about the imbanlance of labels. In my case, since I don't filter instances bsed on blinking rates, I use micro.\n",
    "    # Ref: https://datascience.stackexchange.com/questions/40900/whats-the-difference-between-sklearn-f1-score-micro-and-weighted-for-a-mult. The 'micro' uses the global number of TP, FN, FP and calculates the F1 directly without favouring any classes.\n",
    "    f1_score = sklearn.metrics.f1_score(y_true, y_pred, average='macro')  # Before resetting the 0-back time equals to the 1,2,3-backs, I use the macro.\n",
    "    \n",
    "    # Get the confusion matrices and display them.\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(cm)\n",
    "    \n",
    "    # Plot the confusion matrix.\n",
    "    ax = plt.figure().subplots()\n",
    "    ax.set(title=model_name + \" MODEL\")\n",
    "    \n",
    "    cm_display.plot(ax=ax)\n",
    "    plt.show()\n",
    "    \n",
    "    return acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fb5c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distributions with a bar chart.\n",
    "# Learnt from the quora here.https://stackoverflow.com/questions/63650646/add-labels-and-title-to-a-plot-made-using-pandas.\n",
    "def plot_class_distribution(df_input, title, x_label, y_label, class_column):\n",
    "    df = df_input.copy()\n",
    "    ax = pd.Series(df[class_column]).value_counts().sort_index()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    ax.plot(kind='bar')\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d208aa8",
   "metadata": {},
   "source": [
    "#### Clean the instances and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9232c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select validated rows/instances by thresholdings.\n",
    "def validate_instances(args, df_input):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "#     # Plot the original class distributions.\n",
    "#     plot_class_distribution(df_input=df, title='Original instances - class distribution', x_label='Classes', y_label='Instances', class_column=LABELS) # class distributions before.\n",
    "    \n",
    "    # Remove instances with high blinking rates.\n",
    "    before_blinking_filter = len(df)\n",
    "    df = df.loc[df[ISBLINK_LEFT] <= args.blinking_rate_threshold]\n",
    "    df = df.loc[df[ISBLINK_RIGHT] <= args.blinking_rate_threshold]\n",
    "    after_blinking_filter = len(df)\n",
    "    lost_data_num = before_blinking_filter - after_blinking_filter\n",
    "    print('The blinking threshold is: ' + str(args.blinking_rate_threshold) + '. Before there was: ' + str(before_blinking_filter) + ' instances, then there is : ' + str(after_blinking_filter) + ' instances. ' + str(lost_data_num) + ' instances are lost.')\n",
    "    plot_class_distribution(df_input=df, title='Tuned instances - class distribution', x_label='Classes', y_label='Instances', class_column=LABELS) # Show the class distributions after tuning.\n",
    "    \n",
    "#     # Try with less classes.\n",
    "#     df = df.loc[df[LABELS] < 3] # Try with 3 labels: 0, 1, 2 since LHIPA was not sensitive to the THREEBACKs.\n",
    "#     df = df.loc[df[LABELS] != 1] # Try with 3 labels: 0, 2 since LHIPA was not sensitive to these 2 classes. dfObj[(dfObj['Sale'] > 30) & (dfObj['Sale'] < 33) ]\n",
    "    \n",
    "    df_train = df.loc[df[PID] != 9] # <TODO: this part needs to be improved>\n",
    "    df_test = df_train\n",
    "#     df_test = df.loc[df[PID] == 8]\n",
    "    \n",
    "    \n",
    "#     # Reset the index.\n",
    "#     df = df.reset_index()\n",
    "#     df = df.loc[:, df.columns != 'index']\n",
    "    \n",
    "    # Get the output.\n",
    "    df_output = df.copy()\n",
    "    \n",
    "    df_output_train = df_train.copy()\n",
    "    df_output_test = df_test.copy()\n",
    "    \n",
    "    return df_output_train, df_output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d2337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(df_input, selected_feature_sets, dropped_feature_sets):\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # Feature selection\n",
    "    # Remove PID label / feature.\n",
    "    df = df.loc[:, df.columns != PID]\n",
    "    \n",
    "    # Remove lux\n",
    "    df = df.loc[:, df.columns != LUX]\n",
    "    \n",
    "    # Remove the blinking rates related features.\n",
    "    df = df.loc[:, df.columns != ISBLINK_LEFT]\n",
    "    df = df.loc[:, df.columns != ISBLINK_RIGHT]\n",
    "    \n",
    "    # Select features according to needs.\n",
    "    if dropped_feature_sets is False and selected_feature_sets is not False:\n",
    "#         selected_feature_sets.append(ISBLINK_LEFT)\n",
    "#         selected_feature_sets.append(ISBLINK_RIGHT)\n",
    "#         selected_feature_sets.append(LUX)\n",
    "        \n",
    "        selected_feature_sets.append(LABELS)\n",
    "        df_output = df[selected_feature_sets] \n",
    "        \n",
    "        # Remove appended features.\n",
    "        selected_feature_sets.remove(LABELS)\n",
    "#         selected_feature_sets.remove(ISBLINK_LEFT)\n",
    "#         selected_feature_sets.remove(ISBLINK_RIGHT)\n",
    "#         selected_feature_sets.remove(LUX)\n",
    "    elif selected_feature_sets is False and dropped_feature_sets is not False:\n",
    "        for feature in dropped_feature_sets:\n",
    "            df = df.loc[:, df.columns != feature]\n",
    "        df_output = df.copy()\n",
    "    elif dropped_feature_sets is False and selected_feature_sets is False:\n",
    "        df_output = df.copy()\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4804740",
   "metadata": {},
   "source": [
    "#### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b077763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the models, get the results.\n",
    "def train_test_models(args, df_input, df_test, label_string): # <TODO> need to modify later.\n",
    "    # Split dataset.\n",
    "    \n",
    "    # K-fold way.\n",
    "    df = df_input.copy()\n",
    "    # Get the X and y sets.\n",
    "    X = df.loc[:, df.columns != LABELS].to_numpy()\n",
    "    y = df.loc[:, df.columns == LABELS].to_numpy()\n",
    "    y = np.reshape(y, -1)\n",
    "    \n",
    "#     # Split the data into training dataset and validation dataset.\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=args.test_size_pct, random_state=999)\n",
    "\n",
    "###################################### Testing area #################################\n",
    "#     df_test = df_test.copy()\n",
    "    \n",
    "#     X_train = df.loc[:, df.columns != LABELS].to_numpy()\n",
    "#     y_train = df.loc[:, df.columns == LABELS].to_numpy()\n",
    "#     y_train = np.reshape(y_train, -1)\n",
    "    \n",
    "#     X_test = df_test.loc[:, df_test.columns != LABELS].to_numpy()\n",
    "#     y_test = df_test.loc[:, df_test.columns == LABELS].to_numpy()\n",
    "#     y_test = np.reshape(y_test, -1)\n",
    "######################################################################################\n",
    "    \n",
    "    # Train with models.\n",
    "    print('------------------------------------------------' + label_string + ' Model ------------------------------------------------')\n",
    "    \n",
    "#     # SVM model. TODO: try the SVM model mentioned in 2022 ISMAR and boosting method, and also feature selection method.\n",
    "#     clf_svm = make_pipeline(StandardScaler(),SVC(kernel='poly', degree=7)) #SVC(kernel='rbf', gamma='auto'))\n",
    "#     # Try SVM, bacause it is one of the most widely used models in cognitive workload claissfications.\n",
    "#     clf_svm.fit(X_train, y_train)\n",
    "#     y_pred_svm = clf_svm.predict(X_test)\n",
    "#     score_svm = show_performance(y_true=y_test, y_pred=y_pred_svm, model_name = SVM)\n",
    "#     acc_score_svm = 0\n",
    "    \n",
    "#     # KNN model.\n",
    "#     clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#     # Train the model.\n",
    "#     clf_knn.fit(X_train, y_train)\n",
    "#     # Test.\n",
    "#     y_pred_knn = clf_knn.predict(X_test)\n",
    "#     acc_score_knn, f1_score_knn = show_performance(y_true=y_test, y_pred=y_pred_knn, model_name = KNN)\n",
    "    \n",
    "#     # Random Forest model.\n",
    "#     clf_rf = RandomForestClassifier(max_depth=args.rf_depth, random_state=999)\n",
    "#     # Train the model.\n",
    "#     clf_rf.fit(X_train, y_train)\n",
    "#     # Test.\n",
    "#     y_pred_rf = clf_rf.predict(X_test)\n",
    "#     acc_score_rf, f1_score_rf = show_performance(y_true=y_test, y_pred=y_pred_rf, model_name = RF)\n",
    "    \n",
    "#     # Print the results.\n",
    "#     print('\\nThe KNN accuracy is: ' + str(acc_score_knn) +  '\\nThe RF accuracy is: ' + str(acc_score_rf))\n",
    "#     print('\\nThe KNN F1 is: ' + str(f1_score_knn) +  '\\nThe RF F1 is: ' + str(f1_score_rf))\n",
    "#     print('\\nThe used features are: ') # Briefly display the features utilized.\n",
    "#     print(df)\n",
    "\n",
    "    # Try the nested cross-validation, referred from: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html.\n",
    "    # Number of random trials\n",
    "    NUM_TRIALS = 20\n",
    "\n",
    "    # Random Forest model.\n",
    "    clf_rf = RandomForestClassifier(max_depth=args.rf_depth, random_state=999)\n",
    "    \n",
    "    # Set up possible values of parameters to optimize over.\n",
    "    para_grid = {'max_depth': [3, 5, 8, 10, 13, 15, 20]}\n",
    "    \n",
    "    # Arrays to store scores.\n",
    "    non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "    nested_scores = np.zeros(NUM_TRIALS)\n",
    "    \n",
    "    # Loop for each trial\n",
    "    for i in range(NUM_TRIALS):\n",
    "        # Log.\n",
    "        print('The current round is: ' + str(i))\n",
    "\n",
    "        # Choose cross-validation techniques for the inner and outer loops,\n",
    "        # independently of the dataset.\n",
    "        # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "        inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "        outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "        # Non_nested parameter search and scoring\n",
    "        clf = GridSearchCV(estimator=clf_rf, param_grid=para_grid, cv=outer_cv)\n",
    "        clf.fit(X, y)\n",
    "        non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "        # Nested CV with parameter optimization\n",
    "        clf = GridSearchCV(estimator=clf_rf, param_grid=para_grid, cv=inner_cv)\n",
    "        nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "        nested_scores[i] = nested_score.mean()\n",
    "\n",
    "    score_difference = non_nested_scores - nested_scores\n",
    "    \n",
    "    print(\n",
    "        \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
    "            score_difference.mean(), score_difference.std()\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Output the data.\n",
    "    df_output = df.copy()\n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca86c0f1",
   "metadata": {},
   "source": [
    "#### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "386c4d8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The pipeline for experiments.\n",
    "def run(args):\n",
    "    # Read in data from the csv file.\n",
    "    filepath = args.path\n",
    "    df_raw_features = pd.read_csv(filepath)\n",
    "    \n",
    "    # Encode features into numeric values.\n",
    "    df_numeric_features = encode(df_input=df_raw_features)\n",
    "\n",
    "    # Get validated instances.\n",
    "    df_train, df_test = validate_instances(args=args, df_input=df_numeric_features)\n",
    "\n",
    "\n",
    "    # Looping and fine-tuning hyper-parameters. <TODO>\n",
    "\n",
    "    # Compare different features.\n",
    "#     # Time-domain baseline feature sets.\n",
    "#     time_domain_features = [AVE_DM, DIFF_DM, MEAN_LEFT, MEAN_RIGHT, VAR_LEFT, VAR_RIGHT, STD_LEFT, STD_RIGHT, MAX_LEFT, MAX_RIGHT, SKEW_LEFT, SKEW_RIGHT, MED_LEFT, MED_RIGHT]\n",
    "#     df_baseline_time_features = select_features(df_input=df_train, selected_feature_sets=time_domain_features, dropped_feature_sets=False)\n",
    "#     # train_test_models(df_input=df_baseline_time_features, label_string='Time-domain-based Features')\n",
    "\n",
    "#     df_baseline_time_features_test = select_features(df_input=df_test, selected_feature_sets=time_domain_features, dropped_feature_sets=False)\n",
    "#     train_test_models(args=args, df_input=df_baseline_time_features, df_test=df_baseline_time_features_test, label_string='Time-domain-based Features')\n",
    "\n",
    "    # # Freqeuncy baseline feature sets.\n",
    "    # freq_domain_ipa_features = [IPA_LEFT, IPA_RIGHT]\n",
    "    # df_baseline_freq_features_ipa = select_features(df_input=df_all_features, selected_feature_sets=freq_domain_ipa_features, dropped_feature_sets=False)\n",
    "    # train_test_models(df_input=df_baseline_freq_features_ipa, label_string='Freq-domain-based IPA Features')\n",
    "\n",
    "    # freq_domain_lhipa_features = [LHIPA_LEFT, LHIPA_RIGHT]\n",
    "    # df_baseline_freq_features_lhipa = select_features(df_input=df_all_features, selected_feature_sets=freq_domain_lhipa_features, dropped_feature_sets=False)\n",
    "    # train_test_models(df_input=df_baseline_freq_features_lhipa, label_string='Freq-domain-based LHIPA Features')\n",
    "\n",
    "    # # Only wavelet coefficients features.\n",
    "    # dropped_IPA_LHIPA_AVE_DIFF = [AVE_DM, DIFF_DM, IPA_LEFT, IPA_RIGHT, LHIPA_LEFT, LHIPA_RIGHT]\n",
    "    # df_only_coefs = select_features(df_input=df_all_features, selected_feature_sets=False, dropped_feature_sets=dropped_IPA_LHIPA_AVE_DIFF)\n",
    "    # train_test_models(df_input=df_only_coefs, label_string='Only Wavelet Coefficients Features')\n",
    "\n",
    "    # IPA LHIPA and AVE_DM + DF_DM features.\n",
    "    freq_time_baseline_features = [AVE_DM, DIFF_DM, MEAN_LEFT, MEAN_RIGHT, VAR_LEFT, VAR_RIGHT, STD_LEFT, STD_RIGHT, MAX_LEFT, MAX_RIGHT, SKEW_LEFT, SKEW_RIGHT, MED_LEFT, MED_RIGHT,IPA_LEFT, IPA_RIGHT, LHIPA_LEFT, LHIPA_RIGHT]\n",
    "    df_baselines = select_features(df_input=df_train, selected_feature_sets=freq_time_baseline_features, dropped_feature_sets=False)\n",
    "    # train_test_models(df_input=df_baselines, label_string='All Time and Frequency Domain Baseline Features')\n",
    "\n",
    "    df_baselines_test = select_features(df_input=df_test, selected_feature_sets=freq_time_baseline_features, dropped_feature_sets=False)\n",
    "    train_test_models(args=args, df_input=df_baselines, df_test=df_baselines_test, label_string='All Time and Frequency Domain Baseline Features')\n",
    "\n",
    "\n",
    "\n",
    "#     # My proposed feature based features.\n",
    "#     dropped_IPA_LHIPA_features = [IPA_LEFT, IPA_RIGHT, LHIPA_LEFT, LHIPA_RIGHT]\n",
    "#     df_proposed = select_features(df_input=df_train, selected_feature_sets=False, dropped_feature_sets=dropped_IPA_LHIPA_features)\n",
    "#     # train_test_models(df_input=df_proposed, label_string='My Proposed Features')\n",
    "\n",
    "#     df_proposed_test = select_features(df_input=df_test, selected_feature_sets=False, dropped_feature_sets=dropped_IPA_LHIPA_features)\n",
    "#     train_test_models(args=args, df_input=df_proposed, df_test=df_proposed_test, label_string='My Proposed Features')\n",
    "\n",
    "\n",
    "    # # All features baseline.\n",
    "    # df_all_baseline = select_features(df_input=df_all_features, selected_feature_sets=False, dropped_feature_sets=False)\n",
    "    # train_test_models(df_input=df_all_baseline, label_string='All Features')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba05a585",
   "metadata": {},
   "source": [
    "#### Implementation - My Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76544c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate arguments.\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-f')\n",
    "    parser.add_argument(\"--path\", type=str, default='../Data/Results/23-11-16-17/results.csv', \n",
    "                        help=\"The path to read processed features.\")\n",
    "#     parser.add_argument('--using_cuda', type=bool, default=True,\n",
    "#                         help='cuda/cpu')\n",
    "#     parser.add_argument('--gpu_ids', type=bool, default=[0],\n",
    "#                         help='cuda/cpu')\n",
    "#     parser.add_argument('--argument_save_path', type=str, default='../Data/Results/',  # TODO: add the results output stream.\n",
    "#                         help='The path to save arguments.')\n",
    "#     parser.add_argument('--results_save_path', type=str, default='../Data/Results/',\n",
    "#                     help='The path to save processed data and generated features.')\n",
    "#     parser.add_argument('--results_csv_filename', type=str, default='results.csv',\n",
    "#                     help='The result csv filename.')\n",
    "    parser.add_argument('--test_size_pct', type=float, default=0.1,\n",
    "                        help='The percentage of the test size.')\n",
    "    parser.add_argument('--blinking_rate_threshold', type=float, default=1.00,\n",
    "                        help='The threshold of filtering invalid data with low blinking rates.')\n",
    "    parser.add_argument('--rf_depth', type=int, default=10,\n",
    "                        help='The max depth of the random forest model.')\n",
    "    return parser.parse_args(args = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05261e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blinking threshold is: 1.0. Before there was: 10690 instances, then there is : 10690 instances. 0 instances are lost.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------All Time and Frequency Domain Baseline Features Model ------------------------------------------------\n",
      "The current round is: 0\n",
      "The current round is: 1\n",
      "The current round is: 2\n",
      "The current round is: 3\n",
      "The current round is: 4\n",
      "The current round is: 5\n",
      "The current round is: 6\n",
      "The current round is: 7\n",
      "The current round is: 8\n",
      "The current round is: 9\n",
      "The current round is: 10\n",
      "The current round is: 11\n",
      "The current round is: 12\n",
      "The current round is: 13\n",
      "The current round is: 14\n",
      "The current round is: 15\n",
      "The current round is: 16\n",
      "The current round is: 17\n",
      "The current round is: 18\n",
      "The current round is: 19\n",
      "Average difference of 0.000014 with std. dev. of 0.000054.\n"
     ]
    }
   ],
   "source": [
    "# Implement.\n",
    "# Get arguments.\n",
    "args = parse_args()\n",
    "# Run the pipeline\n",
    "run(args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37996451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and make them into processable formalities.\n",
    "# filepath = '../Data/Results/21-11-13-13/results.csv' # Without ipa and lhipa features.\n",
    "# filepath = '../Data/Results/22-11-22-23/results.csv' # With ipa and lhipa features. Sliding window: 5:3.\n",
    "# filepath = '../Data/Results/23-11-09-08/results.csv' # With ipa and lhipa features. Sliding window: 5:4.\n",
    "# filepath = '../Data/Results/23-11-09-51/results.csv' # With ipa and lhipa features. Sliding window: 2:1.6\n",
    "# filepath = '../Data/Results/23-11-12-48/results.csv' # With ipa and lhipa features. Sliding window: 8-7\n",
    "# filepath = '../Data/Results/23-11-14-06/results.csv' # With ipa and lhipa features. Sliding window: 10-8 \n",
    "# filepath = '../Data/Results/23-11-14-24/results.csv' # With ipa and lhipa features. Sliding window: 10-9.5 --> # The longer the window, the more data, the better.\n",
    "# filepath = '../Data/Results/23-11-15-59/results.csv' # Inclueded the PD statistical features. The best. Sliding window: 5-4.5 --> 0.98 --> Without lux, blinking rates, the pure time baseline and baseline + IPA, LHIPA would be still be great: 0.94; 0.96\n",
    "# filepath = '../Data/Results/23-11-16-17/results.csv'# Inclueded the PD statistical features. Sliding window: 10-9.5 --> 0.988;0.989\n",
    "# filepath = '../Data/Results/23-11-16-24/results.csv'# Inclueded the PD statistical features. Sliding window: 4-3.5 --> 0.92;0.88\n",
    "# filepath = '../Data/Results/23-11-16-55/results.csv'# Inclueded the PD statistical features. Sliding window: 4-3 --> 0.96;0.96\n",
    "# filepath = '../Data/Results/23-11-16-36/results.csv'# Inclueded the PD statistical features. Sliding window: 5-4 --> 0.94;0.95\n",
    "# filepath = '../Data/Results/23-11-16-43/results.csv'# Inclueded the PD statistical features. Sliding window: 5-2.5 --> 0.88;0.89\n",
    "\n",
    "# filepath = '../Data/Results/23-11-18-07/results.csv'# Inclueded the PD statistical features. All participants, include RZ(04) and ZL (05). Sliding window: 4-3 -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
